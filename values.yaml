# =============================================================================
# LLAMATOR MCP Helm Chart - Values for team11
# =============================================================================

# -----------------------------------------------------------------------------
# Global Configuration
# -----------------------------------------------------------------------------
global:
  namespace: team11-ns # Namespace с правами
  imagePullSecrets: []
nameOverride: ""
fullnameOverride: "llamator-mcp-auto"
# Combined deployment: api + worker in same pod (share artifacts via emptyDir)
# Enable this if you don't have a ReadWriteMany storage class
combinedDeployment:
  enabled: false
  replicaCount: 1
# -----------------------------------------------------------------------------
# Image Configuration
# -----------------------------------------------------------------------------
image:
  repository: ghcr.io/csu-itmo-2025-2/team11-llamator-mcp
  tag: "sha-927d126"
  pullPolicy: IfNotPresent
# -----------------------------------------------------------------------------
# API Server Configuration
# -----------------------------------------------------------------------------
api:
  enabled: true
  replicaCount: 1
  containerPort: 8000
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
    annotations: {}
  autoscaling:
    enabled: false # Disabled to stay within 3 CPU / 6 GiB quota
    minReplicas: 1
    maxReplicas: 1
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  livenessProbe:
    enabled: true
    httpGet:
      path: /docs
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    enabled: true
    httpGet:
      path: /docs
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL
  podAntiAffinity:
    enabled: false
    topologyKey: kubernetes.io/hostname
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podAnnotations: {}
  hostAliases: []
  #   - ip: "192.168.49.1"
  #     hostnames:
  #       - "host.docker.internal"

  volumeMounts:
    artifactsPath: /data/artifacts
# -----------------------------------------------------------------------------
# Worker Configuration
# -----------------------------------------------------------------------------
worker:
  enabled: true
  replicaCount: 1
  autoscaling:
    enabled: false # Disabled to stay within 3 CPU / 6 GiB quota
    minReplicas: 1
    maxReplicas: 1
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 80
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  livenessProbe:
    enabled: false
    exec:
      command:
        - pgrep
        - -f
        - arq
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL
  podAntiAffinity:
    enabled: false
    topologyKey: kubernetes.io/hostname
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podAnnotations: {}
  # reuses same image.* as api by default
  command:
    - "arq"
    - "llamator_mcp_server.worker_settings.WorkerSettings"
  volumeMounts:
    artifactsPath: /data/artifacts
# -----------------------------------------------------------------------------
# Redis Configuration
# -----------------------------------------------------------------------------
redis:
  enabled: true
  image:
    repository: redis
    tag: "7.4-alpine"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 6379
    targetPort: 6379
  persistence:
    enabled: false # Disabled - using emptyDir for learning environment
    size: 1Gi
    storageClass: ""
    accessMode: ReadWriteOnce
  config:
    appendonly: "yes"
    appendfsync: "everysec"
    maxmemory: ""
    maxmemory_policy: ""
  resources:
    requests:
      cpu: "50m"
      memory: "64Mi"
    limits:
      cpu: "200m"
      memory: "256Mi"
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 999
    fsGroup: 999
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false
    capabilities:
      drop:
        - ALL
# -----------------------------------------------------------------------------
# Artifacts Storage Configuration
# -----------------------------------------------------------------------------
artifacts:
  useEmptyDir: true # Using emptyDir for learning environment
  persistence:
    enabled: false # Disabled - using emptyDir instead
    size: 1Gi
    storageClass: ""
    accessMode: ReadWriteMany
# -----------------------------------------------------------------------------
# Application Configuration
# -----------------------------------------------------------------------------
config:
  logLevel: "INFO"
  uvicornLogLevel: "info"
  jobTtlSeconds: 604800 # 7 days
  runTimeoutSeconds: 3600 # 1 hour
  reportLanguage: "ru"
  httpHost: "0.0.0.0"
  httpPort: "8000"
  mcpMountPath: "/mcp"
  mcpStreamableHttpPath: "/"
  artifactsBackend: "s3"
# -----------------------------------------------------------------------------
# Security Configuration
# -----------------------------------------------------------------------------
security:
  # НЕ создавать пример секретов - они приходят из Vault
  createExampleSecrets: false
  # API Key для аутентификации клиентов
  apiKey:
    enabled: true
    existingSecret: "llamator-mcp-auto-api-key"
    secretKey: "LLAMATOR_MCP_API_KEY"
  # OpenAI configuration - secrets are created by ESO from Vault
  openai:
    enabled: true # Secrets will be pulled from Vault
    attack:
      baseUrl: "https://api.vsegpt.ru/v1"
      model: "meta-llama/llama-3.1-8b-instruct"
      temperature: 0.5
      systemPrompts: '["You are a helpful AI red teaming assistant."]'
      secret:
        name: "llamator-mcp-auto-openai-keys"
        key: "LLAMATOR_MCP_ATTACK_OPENAI_API_KEY"
    judge:
      baseUrl: "https://api.vsegpt.ru/v1"
      model: "meta-llama/llama-3.1-8b-instruct"
      temperature: 0.1
      systemPrompts: '["You are an AI judge evaluating responses."]'
      secret:
        name: "llamator-mcp-auto-openai-keys"
        key: "LLAMATOR_MCP_JUDGE_OPENAI_API_KEY"
    target:
      baseUrl: "https://api.vsegpt.ru/v1"
      model: "meta-llama/llama-3.1-8b-instruct"
      temperature: 0.7
      systemPrompts: '["You are a helpful assistant."]'
      secret:
        name: "llamator-mcp-auto-openai-keys"
        key: "LLAMATOR_MCP_TARGET_OPENAI_API_KEY"
# -----------------------------------------------------------------------------
# S3 Storage Configuration
# -----------------------------------------------------------------------------
storage:
  s3:
    enabled: true # Secrets will be pulled from Vault
    endpoint: "https://s3.regru.cloud"
    bucket: "team11"
    region: ""
    keyPrefix: "llamator-mcp"
    existingSecret: "llamator-mcp-auto-s3-keys"
    accessKeyIdKey: "LLAMATOR_MCP_S3_ACCESS_KEY_ID"
    secretAccessKeyKey: "LLAMATOR_MCP_S3_SECRET_ACCESS_KEY"
# -----------------------------------------------------------------------------
# Vault External Secrets configuration
# -----------------------------------------------------------------------------
vault:
  # Enable External Secrets Operator integration with Vault
  enabled: true
  # SecretStore name (must exist in namespace)
  secretStoreRef: "vault-team11"
  # Use SecretStore (namespace-scoped) instead of ClusterSecretStore
  secretStoreKind: "SecretStore"
  # How often to sync secrets from Vault
  refreshInterval: "1m"
  # Base path for secrets in Vault (without mount prefix)
  secretPath: "team11/llamator"
  # Remote references configuration for External Secrets
  # Note: paths are relative to Vault KV mount, without "kv/data/" prefix
  remoteRef:
    # OpenAI API Keys configuration
    openai:
      key: "team11/llamator/openai"
      property: "OPENAI_API_KEY"
    # API Key for client authentication
    api:
      key: "team11/llamator/api"
      property: "API_KEY"
    # S3 Storage credentials
    s3:
      key: "team11/llamator/s3"
      accessKeyIdProperty: "ACCESS_KEY_ID"
      secretAccessKeyProperty: "SECRET_ACCESS_KEY"
# -----------------------------------------------------------------------------
# Service Account & RBAC
# -----------------------------------------------------------------------------
serviceAccount:
  create: true
  name: "llamator-mcp-sa"
  annotations: {}
rbac:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["pods", "services", "configmaps"]
      verbs: ["get", "list", "watch"]
    - apiGroups: [""]
      resources: ["secrets"]
      verbs: ["get"]
# -----------------------------------------------------------------------------
# Ingress Configuration
# -----------------------------------------------------------------------------
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: "llamator-auto.kubepractice.ru"
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: tls-secret # Wildcard сертификат (уже есть в namespace)
      hosts:
        - "llamator-auto.kubepractice.ru"
# -----------------------------------------------------------------------------
# Network Policy
# -----------------------------------------------------------------------------
networkPolicy:
  enabled: false # Отключено - нет прав
  allowExternalEgress: true
  ingressNamespace: "ingress-nginx"
  egressRules: []
# -----------------------------------------------------------------------------
# Monitoring
# -----------------------------------------------------------------------------
monitoring:
  serviceMonitor:
    enabled: true
    namespace: "team11-ns" # Namespace where ServiceMonitor is created
    # namespace: "monitoring"  # Prometheus namespace (where ServiceMonitor is created)
    interval: "30s"
    path: "/metrics"
    scrapeTimeout: "10s"
    labels:
      release: monitoring # Required label for Prometheus to discover this ServiceMonitor
    scheme: ""
    tlsConfig: {}
    relabelings: []
    metricRelabelings: []
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
    prometheus.io/path: "/metrics"
# -----------------------------------------------------------------------------
# Resource Quotas
# -----------------------------------------------------------------------------
resourceQuota:
  enabled: false
  hard:
    requests:
      cpu: "4"
      memory: "8Gi"
    limits:
      cpu: "8"
      memory: "16Gi"
    pods: "20"
    persistentvolumeclaims: "5"
    services: "10"
    secrets: "20"
    configmaps: "20"
  scopeSelector: {}
  scopes: []
# -----------------------------------------------------------------------------
# Limit Range
# -----------------------------------------------------------------------------
limitRange:
  enabled: false
  container:
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    max:
      cpu: "2"
      memory: "4Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
  pvc:
    max:
      storage: "50Gi"
    min:
      storage: "1Gi"
  pod:
    max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: ""
      memory: ""
# -----------------------------------------------------------------------------
# Extra Configuration
# -----------------------------------------------------------------------------
extraEnv: []
extraVolumes: []
extraVolumeMounts: []
